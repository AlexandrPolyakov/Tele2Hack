{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#стемминг\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "#обработаем тексты: токен, стоп-слова, стемминг. \n",
    "stop_w = set(stopwords.words('russian'))\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "stemmer = SnowballStemmer(\"russian\") \n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "stop_w_eng = set(stopwords.words('english'))\n",
    "    \n",
    "#Стоп-слова\n",
    "voc = ['date', 'maslov', 'artemova', 'shvyryaeva', 'стр', 'тд', 'зао', 'ао', 'ооо',\n",
    "       'трофимов', 'trofimov', 'mail', 'dzhadigerova', 'skripnik', 'bedina', 'syshchikova', \n",
    "       'средний', 'катя', 'этаж', 'шоссе', 'км', 'куприянов', 'kupriyanova', 'korepova', \n",
    "      'ya', 'butenko', 'chebotareva', 'чеботарев', 'чеботарев', 'сидоренко', 'бутенко',\n",
    "       'yudintseva', 'шишков', 'лена', 'почему', 'чеботарев', 'sidorenko', 'dolzhikova',\n",
    "       'лукьянов', 'отдел', 'дя', 'сказать', 'inna', 'инна', 'vyacheslav', 'вячеслав', \n",
    "       'санкт', 'барановская', 'анастасия', 'agafonova', 'nikolaeva', 'николаев', 'зинаида', \n",
    "      'dinar', 'lysenko', 'nina', 'нина', 'marina', 'eduard', 'марина', 'эдуард', 'ilyukhina',\n",
    "       'область','глеб', 'russia', 'division', 'dmitriy', 'vadim', 'daria', 'дарья', 'любовь', \n",
    "       'lyubov', 'diana', 'диана', 'sergeev', 'pavlova', 'sviridova', 'semenova', 'lyudmila', 'yaroslav',\n",
    "       'ярослав', 'ponomarev', 'antonova', 'viktoriya', 'виктория', 'david',  'давид', 'новиков', 'novikov',\n",
    "       'retail', 'polina', 'полина', 'oleg', 'олег', 'viktor', 'dmitriev', 'дмитриев', 'ivanov', 'андрей',\n",
    "       'vitaliy', 'yuliya', 'nikolay', 'николай', 'marat', 'марат', 'подразделение', 'валентин',\n",
    "       'valentin', 'валерий', 'дирекция', 'vera', 'вера', 'отдел', 'cluster', 'мб', 'elen', 'eremin',\n",
    "       'komarov', 'юля', 'alina', 'zhukova', 'bondarev', 'nataliya', 'наталия', 'ivan', 'иван', 'galina',\n",
    "       'галина', 'nikita', 'кроме', 'никита', 'vladimir', 'artem', 'артем', 'natalya', 'якобы', 'петр',\n",
    "       'kovalev', 'ковалев', 'степан', 'сидоров', 'марья', 'уткин', 'valentina', 'валентина', 'александра',\n",
    "       'tamara', 'тамара', 'tarasov', 'тарасов', 'мария', 'mariya', 'morozova', 'gladkova', 'морозов',\n",
    "       'людмила', 'vladislav', 'владислав', 'department', 'direction', 'margarita', 'оно', 'который', 'мы',\n",
    "       'один', 'пожалуйста','алексей', 'мочь', 'это', 'ваш', 'sent', 'дата','помочь', 'срочно', 'заранее',\n",
    "       'пользователь', 'данный', 'два', 'дмитрий', 'коллега', 'александр', 'какой', 'также', 'добрый', 'andrey',\n",
    "       'olga', 'sergey', 'wednesday', 'быть', 'просить', 'свой', 'сергей', 'евгений', 'tuesday', 'просьба', \n",
    "       'elena', 'елена', 'friday', 'уважаемый', 'именно', 'наталья', 'ирина', 'ольга', 'другой', 'сегодня',\n",
    "       'светлана', 'татьяна', 'юлий', 'monday', 'анна', 'владимир', 'екатерина', 'noreply', 'ооо', 'вы', 'фио', \n",
    "       'утро', 'день', 'вечер', 'anton', 'yuferev', 'просто', 'лишь', 'возможно', 'каждый', 'указывать', 'номер',\n",
    "       'необходимо', 'иванов', 'ivanova', 'афанасьев', 'lukashenkova', 'лукашенкова', 'витальевна', 'perevozchikova',\n",
    "       'майоров', 'mayorova', 'плиз','апожалуйст', 'alexander', 'привет', 'квасов', 'ekaterina', 'anna', 'thursday',\n",
    "        'saturday', 'abagova', 'lana', 'shlyapin', 'shiryaeva', 'trifonov', 'yulia', 'svetlana', 'noskov',\n",
    "       'shishkova', 'ане','горбатов','станислав','stanislav', 'plekhanova', 'домовлад', 'домовть', 'natalia',\n",
    "       'dmitry', 'tatiana', 'irina', 'nadezhda', 'alsu', 'evgeniya', 'anastasia', 'maria', 'aleksandra', 'oksana',\n",
    "       'ksenia', 'alexey', 'vyasheslav', 'надежда', 'guseva', 'valeriy', 'свиридов', 'best', 'regards', 'denis',\n",
    "       'денис','antonina', 'антонин', 'victoria','tigran', 'elena', 'роман', 'roman', 'кристина', 'kristina',\n",
    "       'павел', 'alena', 'алена', 'alexandra', 'anatoliy', 'анатолий', 'ivanova', 'igor', 'игорь', 'larisa',\n",
    "       'лариса','абрамов', 'ilya', 'илья', 'yuriy', 'юрий', 'извинение', 'yury', 'markov', 'yana', 'ян', 'вадим',\n",
    "       'литвинов', 'рустам', 'litvinova','руслан','алсу','shirokova', 'широкова','пжл','кирилл', 'maksim', 'zaytsev',\n",
    "       'lapshin', 'петров', 'анастасий', 'dragunova', 'виктор', 'боровиков', 'april', 'тищенко', 'семенов', 'улица',\n",
    "       'the', 'козлов', 'kozlov', 'затем', 'пожалуйста', 'апожалуйст', 'аня', 'россия', 'обл', 'проблема',\n",
    "        'сказать', 'семенова', 'https', 'alekseeva', 'ludmila', 'людмила', 'маша',  'egor', 'егор', 'тамара',\n",
    "           'вячеславовна', 'апожалуйста', 'январь', 'февраль', 'март', 'апрель', 'май', 'июнь','июль','август',\n",
    "       'сентябрь','октябрь','ноябрь','декабрь','january', 'february','march', 'april', 'may', 'june', 'july',\n",
    "       'august', 'september', 'october', 'november', 'december', 'monday', 'sunday', 'saturday','wednesday',\n",
    "       'thursday', 'tuesday', 'friday', 'понедельник', 'вторник', 'четверг', 'пятница', 'суббота', 'воскресенье'] \n",
    "\n",
    "stop_w = list(stop_w) \n",
    "for word in voc:\n",
    "    stop_w.append(word)\n",
    "for word in stop_w_eng:\n",
    "    stop_w.append(word)\n",
    "stop_w = set(stop_w)\n",
    "\n",
    "stop_w = list(stop_w)\n",
    "\n",
    "for word in stop_w_eng:\n",
    "    stop_w.append(word)\n",
    "stop_w = set(stop_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загружаем полные тексты клиентов и тех. поддержки\n",
    "data_clienttexts = pd.read_pickle('data_clienttexts.pickle')\n",
    "data_techtexts = pd.read_pickle('data_textstexts.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Словарь для соответствия городов из разных файлов\n",
    "dict_locations = {'saransk': 'Саранск', 'rostov': 'Ростов-на-Дону', 'krasnodar': 'Краснодар', 'spb': 'Санкт-Петербург', \n",
    "                  'kostroma': 'Кострома', 'moscow': 'Москва', 'nnov': 'Нижний Новгород', 'vladimir': 'Владимир', \n",
    "                 'perm': 'Пермь', 'kazan': 'Казань', 'chelyabinsk': 'Челябинск', 'tver': 'Тверь', 'lipetsk': 'Липецк', \n",
    "                  'vladivostok':  'Владивосток', 'tomsk': 'Томск', 'ekaterinburg': 'Екатеринбург', 'komi':'Коми', \n",
    "                 'barnaul': 'Барнаул', 'novosibirsk': 'Новосибирск', 'krasnoyarsk': 'Красноярск', 'kaliningrad': 'Калининград', \n",
    "                 'vologda': 'Вологда', 'kurgan': 'Курган', 'murmansk': 'Мурманск', 'ryazan': 'Рязань', \n",
    "                 'yoshkar-ola': 'Йошкар-Ола', 'arh': 'Архангельск', 'tyumen': 'Тюмень', 'samara': 'Самара', \n",
    "                 'vnovgorod': 'Великий Новгород', 'izhevsk': 'Ижевск', 'orel': 'Орёл', 'kursk': 'Курск', \n",
    "                 'voronezh': 'Воронеж', 'volgograd': 'Волгоград', 'tambov': 'Тамбов', 'tula': 'Тула', 'smolensk':   'Смоленск', \n",
    "                 'bryansk': 'Брянск', 'kirov': 'Киров',  'hmao':  'Ханты-Мансийск', 'norilsk': 'Норильск', \n",
    "                 'petrozavodsk': 'Петрозаводск', 'irkutsk': 'Иркутск', 'kaluga': 'Калуга', 'omsk': 'Омск', \n",
    "                 'belgorod': 'Белгород', 'penza': 'Пенза', 'orenburg': 'Оренбург', 'cheboksary': 'Чебоксары', \n",
    "                 'abakan': 'Абакан', 'kamchatka': 'Камчатка', 'saratov': 'Саратов', 'sakhalin': 'Сахалин', 'pskov': 'Псков', \n",
    "                 'ulyanovsk': 'Ульяновск', 'magadan': 'Магадан', 'kuzbass': 'Кузбасс', 'buryatia': 'Бурятия', \n",
    "                 'yanao': 'Салехард'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#Приводим города к одному виду\n",
    "def city_recognize(text):\n",
    "    text = re.sub('B2C', '', text)\n",
    "    text = re.sub('Скайлинк', '', text)\n",
    "    text = re.sub('B2B', '', text)\n",
    "    try:\n",
    "        text = dict_locations[text]\n",
    "    except KeyError:\n",
    "        text = text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Приводим города к одному виду\n",
    "data_clienttexts.location = data_clienttexts.location.apply(city_recognize)\n",
    "data_techtexts.location = data_techtexts.location.apply(city_recognize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Исправляем опечатки\n",
    "import jamspell\n",
    "corrector = jamspell.TSpellCorrector()\n",
    "corrector.LoadLangModel('/Users/alexanpolyakov/Downloads/ru_small.bin')\n",
    "\n",
    "#Лемматизация\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "#Токенизация текста\n",
    "def tokenize(text):\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    text=text.lower()\n",
    "    text = re.sub('pin', 'пинкод', text)\n",
    "    text = re.sub('puk', 'пуккод', text)\n",
    "    text = re.sub('sim', 'сим', text)\n",
    "    text = re.sub('3g', 'триджи', text)\n",
    "    text = re.sub('4g', 'четыреджи', text)\n",
    "    text = re.sub('lte', 'лте', text)\n",
    "    text = re.sub('nfs', 'нфс', text)\n",
    "    text = re.sub('[^а-яё]+', ' ', text)\n",
    "    text = re.sub('ё', 'е', text)\n",
    "    text = re.sub('\\s?теле\\s+', ' теледва ', text)\n",
    "    \n",
    "    text = corrector.FixFragment(text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    text = ' '.join(m.lemmatize(text))\n",
    "    \n",
    "    for word in tokenizer.tokenize(text):\n",
    "        if word not in stop_w and len(word) > 1:\n",
    "            tokens.append(word)\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clienttexts.text = data_clienttexts.text.apply(str)\n",
    "data_techtexts.text = data_techtexts.text.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Делаем лемматизацию ответов тех. поддержки\n",
    "data_techtexts.text = data_techtexts.text.apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_techtexts.to_pickle('data_techtexts_lem.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Тематическое моделирование с распределением Дирихле\n",
    "#Строим две модели кластеризации:\n",
    "    #Для текстов клиентов\n",
    "    #Для тексто тех. поддержки\n",
    "#Далее по паре кластеров определяем ответ из стандартного faq Tele2, если клиент не жалобщик\n",
    "# и вероятность принадлежности кластерам достаточно высока(Следует подбирать из результатов, например, 0.5)\n",
    "from gensim import corpora\n",
    "texts_clients = [data_clienttexts.iloc[i].text.split(' ') for i in range(len(data_clienttexts))]\n",
    "dictionary_clients = corpora.Dictionary(texts_clients)\n",
    "dictionary_clients.filter_extremes(no_below = 200, no_above = 0.34)\n",
    "corpus_clients = [dictionary_clients.doc2bow(text) for text in texts_clients]\n",
    "#Следующий файл - финальный\n",
    "#Затем чат-бот(не основная часть, дополнение к идее) и файлы для сервера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(lda_MC_clients, open('lda_MC_clients.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lda_MC_tech, open('lda_MC_tech.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(texts_clients, open('texts_clients.pickle', 'wb'))\n",
    "pickle.dump(texts_tech, open('texts_tech.pickle', 'wb'))\n",
    "pickle.dump(dictionary_clients, open('dictionary_clients.pickle', 'wb'))\n",
    "pickle.dump(dictionary_tech, open('dictionary_tech.pickle', 'wb'))\n",
    "pickle.dump(corpus_clients, open('corpus_clients.pickle', 'wb'))\n",
    "pickle.dump(corpus_tech, open('corpus_tech.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(texts_tech, open('texts_tech.pickle', 'wb'))\n",
    "pickle.dump(dictionary_tech, open('dictionary_tech.pickle', 'wb'))\n",
    "pickle.dump(corpus_tech, open('corpus_tech.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_techtexts = pd.read_pickle('data_techtexts_lem.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Тематическое моделирование с распределением Дирихле\n",
    "#Строим две модели кластеризации:\n",
    "    #Для текстов клиентов\n",
    "    #Для тексто тех. поддержки\n",
    "lda_MC_clients = models.LdaMulticore(corpus_clients, id2word=dictionary_clients, num_topics=25, workers=4, passes=15, iterations=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tech = [data_techtexts.iloc[i].text.split(' ') for i in range(len(data_techtexts))]\n",
    "dictionary_tech = corpora.Dictionary(texts_tech)\n",
    "dictionary_tech.filter_extremes(no_below = 200, no_above = 0.34)\n",
    "corpus_tech = [dictionary_tech.doc2bow(text) for text in texts_tech]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 3s, sys: 2min 4s, total: 13min 7s\n",
      "Wall time: 18min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_MC_tech = models.LdaMulticore(corpus_tech, id2word=dictionary_tech, num_topics=25, workers=4, passes=15, iterations=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Смотрели частоты слов словаря\n",
    "from operator import itemgetter\n",
    "dictionary_reverse = {v:k for k,v in dictionary.items()}\n",
    "\n",
    "words_frequences = []\n",
    "for word in dictionary_reverse:\n",
    "    elem = (word,dictionary.dfs[dictionary_reverse[word]])\n",
    "    words_frequences.append(elem)\n",
    "    \n",
    "sorted_words_frequences = sorted(words_frequences, key = itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clienttexts.to_pickle('data_clienttexts_lem.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
